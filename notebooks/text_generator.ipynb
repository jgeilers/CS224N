{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"text_generator.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"caa885ab1d434cb0b55d3b94cdc38fdb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_430ba0b0b3f74fb9a5f0bf8cbb300971","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a1c2655386374a58a76c15a706b780d4","IPY_MODEL_3c6f5ad64cf147e89f45b009a63a70c0"]}},"430ba0b0b3f74fb9a5f0bf8cbb300971":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a1c2655386374a58a76c15a706b780d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_34074bc82eb843aeb8a16507ea2ba598","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d22dac029c584d87a200f04a32ec382c"}},"3c6f5ad64cf147e89f45b009a63a70c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_05f9fbbbca5a4b1bbc4976017884c83b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"â€‹","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 232k/232k [00:00&lt;00:00, 639kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_d7d620993959468a8139d56fb0976505"}},"34074bc82eb843aeb8a16507ea2ba598":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"d22dac029c584d87a200f04a32ec382c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"05f9fbbbca5a4b1bbc4976017884c83b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"d7d620993959468a8139d56fb0976505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"nrguqRamSB_i"},"source":["FORMERLY KNOWN AS BERTO (RIP)"]},{"cell_type":"code","metadata":{"id":"UoIqV33I2rNN"},"source":["!pip install transformers\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"U3yXZMD7oeAd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1615595397703,"user_tz":480,"elapsed":493,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"4339e041-3fda-4e27-e069-5363b6d13600"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","import pandas as pd\n","import shutil\n","import torch\n","import tensorflow as tf\n","import numpy as np\n","from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset, random_split\n","from torch.nn import functional as F\n","import transformers\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification, AdamW, BertConfig\n","from transformers import BertTokenizer, BertForMaskedLM"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hh_SLAh2Fd15","executionInfo":{"status":"ok","timestamp":1615595399475,"user_tz":480,"elapsed":479,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}}},"source":["# CHOOSE MODEL\n","vanilla = 'bert-base-uncased' # this is basic bert and has no saved weights\n","with_davidson = \"bert_train\"\n","with_davidson_parler = \"bert_parler_train\"\n","# with_davidson_4chan = \"bert_4chan_train\" # does not exist yet\n","saved_model = \"saved_model\"\n","big_parler = \"bert_parler_large_train/checkpoint-110000\"\n","\n","# ASSIGN MODEL HERE\n","model_name = big_parler\n","\n","# TRUE IF YOU ARE TESTING MODEL, FALSE IF YOU ARE TRAINING MODEL\n","# train_model = False\n","train_model = True\n","\n","# UNCOMMENT BELOW BASED ON WHO IS RUNNING\n","\n","# for joli (julia/oliver), assuming this works for both\n","prefix = \"/content/drive/MyDrive/CS224N_Project\"\n","\n","# for jackson\n","# prefix = \"/content/drive/MyDrive/Classes/Coterm/Winter Quarter/CS224N/CS224N_Project\"\n","\n","os.chdir(prefix)\n","output_dir = f'{prefix}/model_weights/{model_name}'"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X8L83L6swX5z","executionInfo":{"status":"ok","timestamp":1615595402789,"user_tz":480,"elapsed":571,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"a6955c5b-4b52-4328-8e10-efdbff7fddfd"},"source":["# If there's a GPU available...\n","if torch.cuda.is_available():    \n","\n","    # Tell PyTorch to use the GPU.    \n","    device = torch.device(\"cuda\")\n","\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","\n","# If not...\n","else:\n","    print('No GPU available, using the CPU instead.')\n","    device = torch.device(\"cpu\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla V100-SXM2-16GB\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WrYTLZy6wqyy","executionInfo":{"status":"ok","timestamp":1615595408064,"user_tz":480,"elapsed":3658,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"dcb5af55-c717-4f9c-a0a9-1c716fa2af5f"},"source":["# Get the GPU device name.\n","device_name = tf.test.gpu_device_name()\n","\n","# The device name should look like the following:\n","if device_name == '/device:GPU:0':\n","    print('Found GPU at: {}'.format(device_name))\n","else:\n","    raise SystemError('GPU device not found')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Found GPU at: /device:GPU:0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":83,"referenced_widgets":["caa885ab1d434cb0b55d3b94cdc38fdb","430ba0b0b3f74fb9a5f0bf8cbb300971","a1c2655386374a58a76c15a706b780d4","3c6f5ad64cf147e89f45b009a63a70c0","34074bc82eb843aeb8a16507ea2ba598","d22dac029c584d87a200f04a32ec382c","05f9fbbbca5a4b1bbc4976017884c83b","d7d620993959468a8139d56fb0976505"]},"id":"hK9zdQ8Dwqrc","executionInfo":{"status":"ok","timestamp":1615595408679,"user_tz":480,"elapsed":3040,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"43f57aeb-3434-488e-c5e1-1a8e25721ebe"},"source":["# Load the BERT tokenizer.\n","print('Loading BERT tokenizer...')\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["Loading BERT tokenizer...\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"caa885ab1d434cb0b55d3b94cdc38fdb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZVeiPL5Bwqcw"},"source":["\n","\n","# Load BertForSequenceClassification, the pretrained BERT model with a single \n","# linear classification layer on top. \n","model_base = BertForMaskedLM.from_pretrained(\"bert-base-uncased\", return_dict = True)\n","\n","# Tell pytorch to run this model on the GPU.\n","model_base.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"txtv-0Or_f8S"},"source":["model_ex = BertForMaskedLM.from_pretrained(None, state_dict=\"/content/drive/MyDrive/CS224N_Project/model_weights/state_dict_unzip/archive\",\n","                                           config=\"/content/drive/MyDrive/CS224N_Project/model_weights/bert_train/config.json\", return_dict = True)\n","\n","# Tell pytorch to run this model on the GPU.\n","model_ex.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"el7MePp0TKrG"},"source":["TEXT GENERATOR"]},{"cell_type":"code","metadata":{"id":"tRvwDEojLQvv"},"source":["load_model_name = \"\"\n","if model_name != \"bert-based-uncased\":\n","  load_model_name = \"model_weights/\" + model_name\n","else:\n","  load_model_name = model_name\n","\n","tokenizer = BertTokenizer.from_pretrained(load_model_name)\n","model_mask = BertForMaskedLM.from_pretrained(load_model_name, return_dict = True, pad_token_id=tokenizer.eos_token_id)\n","#model_mask = BertForMaskedLM.from_pretrained(\"bert-base-uncased\",    return_dict = True)\n","\n","\n","\n","# encode context the generation is conditioned on\n","input_ids = tokenizer.encode('I enjoy walking with my cute dog', return_tensors='tf')\n","\n","# generate text until the output length (which includes the context length) reaches 50\n","greedy_output = model_mask.generate(input_ids, max_length=50)\n","\n","print(\"Output:\\n\" + 100 * '-')\n","print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6RGJ9mALqZzP","executionInfo":{"status":"ok","timestamp":1615423102725,"user_tz":480,"elapsed":500,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"26f8e7b6-8297-47b4-ec5c-ace0a8558469"},"source":["num_length = 10\n","text = \"Dominion voting machines\"\n","for i in range(num_length):\n","  text_to_gen = text + \" \" + tokenizer.mask_token\n","  input = tokenizer.encode_plus(text_to_gen, return_tensors = \"pt\")\n","  input.to(device)\n","  mask_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)\n","  model_mask.cuda()\n","  output = model_mask(**input)\n","  logits = output.logits\n","  softmax = F.softmax(logits, dim = -1)\n","  mask_word = softmax[0, mask_index, :]\n","  top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]\n","  #first = top_10[0]\n","  for token in top_10:\n","    word = tokenizer.decode([token])\n","    if word != \"!\" and word != \".\" and word != \",\" and word != \"?\" and word != \":\" and word != \")\":\n","      new_sentence = text_to_gen.replace(tokenizer.mask_token, word)\n","      break\n","  text = new_sentence\n","  print(new_sentence)\n","print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Dominion voting machines too\n","Dominion voting machines too much\n","Dominion voting machines too much fraud\n","Dominion voting machines too much fraud ##s\n","Dominion voting machines too much fraud ##s ##j\n","Dominion voting machines too much fraud ##s ##j #\n","Dominion voting machines too much fraud ##s ##j # d\n","Dominion voting machines too much fraud ##s ##j # d #\n","Dominion voting machines too much fraud ##s ##j # d # d\n","Dominion voting machines too much fraud ##s ##j # d # d #\n","Dominion voting machines too much fraud ##s ##j # d # d #\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZSQZOpLr1_n","executionInfo":{"status":"ok","timestamp":1615423055465,"user_tz":480,"elapsed":421,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"51cf7ad3-79ca-4d05-8adf-9cb3d90db786"},"source":["text_to_gen = \"January 6th is \" + tokenizer.mask_token\n","input = tokenizer.encode_plus(text_to_gen, return_tensors = \"pt\")\n","input.to(device)\n","mask_index = torch.where(input[\"input_ids\"][0] == tokenizer.mask_token_id)\n","model_mask.cuda()\n","output = model_mask(**input)\n","logits = output.logits\n","softmax = F.softmax(logits, dim = -1)\n","mask_word = softmax[0, mask_index, :]\n","top_10 = torch.topk(mask_word, 10, dim = 1)[1][0]\n","for token in top_10:\n","  word = tokenizer.decode([token])\n","  print(word)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["coming\n","over\n","now\n","time\n","friday\n","happening\n","wednesday\n","why\n","done\n","ridiculous\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WH_OcATtwqaS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614718897629,"user_tz":360,"elapsed":58111,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"3b02d437-a964-426c-82b2-d2cb152b9017"},"source":["# Get all of the model's parameters as a list of tuples.\n","params = list(model.named_parameters())\n","\n","print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n","\n","print('==== Embedding Layer ====\\n')\n","\n","for p in params[0:5]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== First Transformer ====\\n')\n","\n","for p in params[5:21]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n","\n","print('\\n==== Output Layer ====\\n')\n","\n","for p in params[-4:]:\n","    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The BERT model has 201 different named parameters.\n","\n","==== Embedding Layer ====\n","\n","bert.embeddings.word_embeddings.weight                  (30522, 768)\n","bert.embeddings.position_embeddings.weight                (512, 768)\n","bert.embeddings.token_type_embeddings.weight                (2, 768)\n","bert.embeddings.LayerNorm.weight                              (768,)\n","bert.embeddings.LayerNorm.bias                                (768,)\n","\n","==== First Transformer ====\n","\n","bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.query.bias                (768,)\n","bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n","bert.encoder.layer.0.attention.self.key.bias                  (768,)\n","bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n","bert.encoder.layer.0.attention.self.value.bias                (768,)\n","bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n","bert.encoder.layer.0.attention.output.dense.bias              (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n","bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n","bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n","bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n","bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n","bert.encoder.layer.0.output.dense.bias                        (768,)\n","bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n","bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n","\n","==== Output Layer ====\n","\n","bert.pooler.dense.weight                                  (768, 768)\n","bert.pooler.dense.bias                                        (768,)\n","classifier.weight                                           (3, 768)\n","classifier.bias                                                 (3,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cef6yZLOwqXh"},"source":["# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n","# I believe the 'W' stands for 'Weight Decay fix\"\n","optimizer = AdamW(model.parameters(),\n","                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n","                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n","                )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2wy05OEwqU6"},"source":["from transformers import get_linear_schedule_with_warmup\n","\n","# Number of training epochs. The BERT authors recommend between 2 and 4. \n","# We chose to run for 4, but we'll see later that this may be over-fitting the\n","# training data.\n","epochs = 4\n","\n","# Total number of training steps is [number of batches] x [number of epochs]. \n","# (Note that this is not the same as the number of training samples).\n","total_steps = len(train_dataloader) * epochs\n","\n","# Create the learning rate scheduler.\n","scheduler = get_linear_schedule_with_warmup(optimizer, \n","                                            num_warmup_steps = 0, # Default value in run_glue.py\n","                                            num_training_steps = total_steps)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZRP3iDVrwqR4"},"source":["import numpy as np\n","\n","# Function to calculate the accuracy of our predictions vs labels\n","def flat_accuracy(preds, labels):\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kEiaUgyiwqK5"},"source":["import time\n","import datetime\n","\n","def format_time(elapsed):\n","    '''\n","    Takes a time in seconds and returns a string hh:mm:ss\n","    '''\n","    # Round to the nearest second.\n","    elapsed_rounded = int(round((elapsed)))\n","    \n","    # Format as hh:mm:ss\n","    return str(datetime.timedelta(seconds=elapsed_rounded))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OMFVGy0Zwp9c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614721531925,"user_tz":360,"elapsed":2692371,"user":{"displayName":"Oliver Brady","photoUrl":"","userId":"00042520871958656342"}},"outputId":"91e9dc19-e4b1-40a1-dc5f-2eda938f1a71"},"source":["import random\n","import numpy as np\n","\n","# This training code is based on the `run_glue.py` script here:\n","# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n","\n","# Set the seed value all over the place to make this reproducible.\n","seed_val = 42\n","\n","random.seed(seed_val)\n","np.random.seed(seed_val)\n","torch.manual_seed(seed_val)\n","torch.cuda.manual_seed_all(seed_val)\n","\n","# We'll store a number of quantities such as training and validation loss, \n","# validation accuracy, and timings.\n","training_stats = []\n","\n","# Measure the total training time for the whole run.\n","total_t0 = time.time()\n","\n","# For each epoch...\n","for epoch_i in range(0, epochs):\n","    \n","    # ========================================\n","    #               Training\n","    # ========================================\n","    \n","    # Perform one full pass over the training set.\n","\n","    print(\"\")\n","    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n","    print('Training...')\n","\n","    # Measure how long the training epoch takes.\n","    t0 = time.time()\n","\n","    # Reset the total loss for this epoch.\n","    total_train_loss = 0\n","\n","    # Put the model into training mode. Don't be mislead--the call to \n","    # `train` just changes the *mode*, it doesn't *perform* the training.\n","    # `dropout` and `batchnorm` layers behave differently during training\n","    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n","    model.train()\n","\n","    # For each batch of training data...\n","    for step, batch in enumerate(train_dataloader):\n","\n","        # Progress update every 40 batches.\n","        if step % 40 == 0 and not step == 0:\n","            # Calculate elapsed time in minutes.\n","            elapsed = format_time(time.time() - t0)\n","            \n","            # Report progress.\n","            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n","        if step % 2000 == 0:\n","          model.save_pretrained(\"/content/drive/MyDrive/CS224N_Project/\")\n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n","        # `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","\n","        # Always clear any previously calculated gradients before performing a\n","        # backward pass. PyTorch doesn't do this automatically because \n","        # accumulating the gradients is \"convenient while training RNNs\". \n","        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n","        model.zero_grad()        \n","\n","        # Perform a forward pass (evaluate the model on this training batch).\n","        # The documentation for this `model` function is here: \n","        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","        # It returns different numbers of parameters depending on what arguments\n","        # arge given and what flags are set. For our useage here, it returns\n","        # the loss (because we provided labels) and the \"logits\"--the model\n","        # outputs prior to activation.\n","        \n","        # loss, logits = model(b_input_ids, \n","        #                      token_type_ids=None, \n","        #                      attention_mask=b_input_mask, \n","        #                      labels=b_labels)\n","        output = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","        loss = output.loss\n","        logits = output.logits\n","        # Accumulate the training loss over all of the batches so that we can\n","        # calculate the average loss at the end. `loss` is a Tensor containing a\n","        # single value; the `.item()` function just returns the Python value \n","        # from the tensor.\n","        total_train_loss += loss.item()\n","\n","        # Perform a backward pass to calculate the gradients.\n","        loss.backward()\n","\n","        # Clip the norm of the gradients to 1.0.\n","        # This is to help prevent the \"exploding gradients\" problem.\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","\n","        # Update parameters and take a step using the computed gradient.\n","        # The optimizer dictates the \"update rule\"--how the parameters are\n","        # modified based on their gradients, the learning rate, etc.\n","        optimizer.step()\n","\n","        # Update the learning rate.\n","        scheduler.step()\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_train_loss = total_train_loss / len(train_dataloader)            \n","    \n","    # Measure how long this epoch took.\n","    training_time = format_time(time.time() - t0)\n","\n","    print(\"\")\n","    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n","    print(\"  Training epcoh took: {:}\".format(training_time))\n","        \n","    # ========================================\n","    #               Validation\n","    # ========================================\n","    # After the completion of each training epoch, measure our performance on\n","    # our validation set.\n","\n","    print(\"\")\n","    print(\"Running Validation...\")\n","\n","    t0 = time.time()\n","\n","    # Put the model in evaluation mode--the dropout layers behave differently\n","    # during evaluation.\n","    model.eval()\n","\n","    # Tracking variables \n","    total_eval_accuracy = 0\n","    total_eval_loss = 0\n","    nb_eval_steps = 0\n","\n","    # Evaluate data for one epoch\n","    for batch in validation_dataloader:\n","        \n","        # Unpack this training batch from our dataloader. \n","        #\n","        # As we unpack the batch, we'll also copy each tensor to the GPU using \n","        # the `to` method.\n","        #\n","        # `batch` contains three pytorch tensors:\n","        #   [0]: input ids \n","        #   [1]: attention masks\n","        #   [2]: labels \n","        b_input_ids = batch[0].to(device)\n","        b_input_mask = batch[1].to(device)\n","        b_labels = batch[2].to(device)\n","        \n","        # Tell pytorch not to bother with constructing the compute graph during\n","        # the forward pass, since this is only needed for backprop (training).\n","        with torch.no_grad():        \n","\n","            # Forward pass, calculate logit predictions.\n","            # token_type_ids is the same as the \"segment ids\", which \n","            # differentiates sentence 1 and 2 in 2-sentence tasks.\n","            # The documentation for this `model` function is here: \n","            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n","            # Get the \"logits\" output by the model. The \"logits\" are the output\n","            # values prior to applying an activation function like the softmax.\n","            output = model(b_input_ids, \n","                                   token_type_ids=None, \n","                                   attention_mask=b_input_mask,\n","                                   labels=b_labels)\n","            loss = output.loss\n","            logits = output.logits\n","        # Accumulate the validation loss.\n","        total_eval_loss += loss.item()\n","\n","        # Move logits and labels to CPU\n","        logits = logits.detach().cpu().numpy()\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        # Calculate the accuracy for this batch of test sentences, and\n","        # accumulate it over all batches.\n","        total_eval_accuracy += flat_accuracy(logits, label_ids)\n","        \n","\n","    # Report the final accuracy for this validation run.\n","    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n","    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n","\n","    # Calculate the average loss over all of the batches.\n","    avg_val_loss = total_eval_loss / len(validation_dataloader)\n","    \n","    # Measure how long the validation run took.\n","    validation_time = format_time(time.time() - t0)\n","    \n","    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n","    print(\"  Validation took: {:}\".format(validation_time))\n","\n","    # Record all statistics from this epoch.\n","    training_stats.append(\n","        {\n","            'epoch': epoch_i + 1,\n","            'Training Loss': avg_train_loss,\n","            'Valid. Loss': avg_val_loss,\n","            'Valid. Accur.': avg_val_accuracy,\n","            'Training Time': training_time,\n","            'Validation Time': validation_time\n","        }\n","    )\n","\n","print(\"\")\n","print(\"Training complete!\")\n","\n","print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","======== Epoch 1 / 4 ========\n","Training...\n","  Batch    40  of  1,240.    Elapsed: 0:00:27.\n","  Batch    80  of  1,240.    Elapsed: 0:00:47.\n","  Batch   120  of  1,240.    Elapsed: 0:01:06.\n","  Batch   160  of  1,240.    Elapsed: 0:01:26.\n","  Batch   200  of  1,240.    Elapsed: 0:01:46.\n","  Batch   240  of  1,240.    Elapsed: 0:02:05.\n","  Batch   280  of  1,240.    Elapsed: 0:02:25.\n","  Batch   320  of  1,240.    Elapsed: 0:02:45.\n","  Batch   360  of  1,240.    Elapsed: 0:03:04.\n","  Batch   400  of  1,240.    Elapsed: 0:03:24.\n","  Batch   440  of  1,240.    Elapsed: 0:03:43.\n","  Batch   480  of  1,240.    Elapsed: 0:04:03.\n","  Batch   520  of  1,240.    Elapsed: 0:04:23.\n","  Batch   560  of  1,240.    Elapsed: 0:04:42.\n","  Batch   600  of  1,240.    Elapsed: 0:05:02.\n","  Batch   640  of  1,240.    Elapsed: 0:05:22.\n","  Batch   680  of  1,240.    Elapsed: 0:05:41.\n","  Batch   720  of  1,240.    Elapsed: 0:06:01.\n","  Batch   760  of  1,240.    Elapsed: 0:06:21.\n","  Batch   800  of  1,240.    Elapsed: 0:06:40.\n","  Batch   840  of  1,240.    Elapsed: 0:07:00.\n","  Batch   880  of  1,240.    Elapsed: 0:07:20.\n","  Batch   920  of  1,240.    Elapsed: 0:07:39.\n","  Batch   960  of  1,240.    Elapsed: 0:07:59.\n","  Batch 1,000  of  1,240.    Elapsed: 0:08:19.\n","  Batch 1,040  of  1,240.    Elapsed: 0:08:38.\n","  Batch 1,080  of  1,240.    Elapsed: 0:08:58.\n","  Batch 1,120  of  1,240.    Elapsed: 0:09:17.\n","  Batch 1,160  of  1,240.    Elapsed: 0:09:37.\n","  Batch 1,200  of  1,240.    Elapsed: 0:09:56.\n","\n","  Average training loss: 0.30\n","  Training epcoh took: 0:10:16\n","\n","Running Validation...\n","  Accuracy: 0.91\n","  Validation Loss: 0.24\n","  Validation took: 0:00:48\n","\n","======== Epoch 2 / 4 ========\n","Training...\n","  Batch    40  of  1,240.    Elapsed: 0:00:22.\n","  Batch    80  of  1,240.    Elapsed: 0:00:41.\n","  Batch   120  of  1,240.    Elapsed: 0:01:01.\n","  Batch   160  of  1,240.    Elapsed: 0:01:20.\n","  Batch   200  of  1,240.    Elapsed: 0:01:40.\n","  Batch   240  of  1,240.    Elapsed: 0:02:00.\n","  Batch   280  of  1,240.    Elapsed: 0:02:19.\n","  Batch   320  of  1,240.    Elapsed: 0:02:39.\n","  Batch   360  of  1,240.    Elapsed: 0:02:58.\n","  Batch   400  of  1,240.    Elapsed: 0:03:18.\n","  Batch   440  of  1,240.    Elapsed: 0:03:38.\n","  Batch   480  of  1,240.    Elapsed: 0:03:57.\n","  Batch   520  of  1,240.    Elapsed: 0:04:17.\n","  Batch   560  of  1,240.    Elapsed: 0:04:37.\n","  Batch   600  of  1,240.    Elapsed: 0:04:56.\n","  Batch   640  of  1,240.    Elapsed: 0:05:16.\n","  Batch   680  of  1,240.    Elapsed: 0:05:35.\n","  Batch   720  of  1,240.    Elapsed: 0:05:55.\n","  Batch   760  of  1,240.    Elapsed: 0:06:15.\n","  Batch   800  of  1,240.    Elapsed: 0:06:34.\n","  Batch   840  of  1,240.    Elapsed: 0:06:54.\n","  Batch   880  of  1,240.    Elapsed: 0:07:13.\n","  Batch   920  of  1,240.    Elapsed: 0:07:33.\n","  Batch   960  of  1,240.    Elapsed: 0:07:52.\n","  Batch 1,000  of  1,240.    Elapsed: 0:08:12.\n","  Batch 1,040  of  1,240.    Elapsed: 0:08:32.\n","  Batch 1,080  of  1,240.    Elapsed: 0:08:51.\n","  Batch 1,120  of  1,240.    Elapsed: 0:09:11.\n","  Batch 1,160  of  1,240.    Elapsed: 0:09:30.\n","  Batch 1,200  of  1,240.    Elapsed: 0:09:50.\n","\n","  Average training loss: 0.22\n","  Training epcoh took: 0:10:09\n","\n","Running Validation...\n","  Accuracy: 0.91\n","  Validation Loss: 0.27\n","  Validation took: 0:00:48\n","\n","======== Epoch 3 / 4 ========\n","Training...\n","  Batch    40  of  1,240.    Elapsed: 0:00:22.\n","  Batch    80  of  1,240.    Elapsed: 0:00:41.\n","  Batch   120  of  1,240.    Elapsed: 0:01:01.\n","  Batch   160  of  1,240.    Elapsed: 0:01:20.\n","  Batch   200  of  1,240.    Elapsed: 0:01:40.\n","  Batch   240  of  1,240.    Elapsed: 0:02:00.\n","  Batch   280  of  1,240.    Elapsed: 0:02:19.\n","  Batch   320  of  1,240.    Elapsed: 0:02:39.\n","  Batch   360  of  1,240.    Elapsed: 0:02:58.\n","  Batch   400  of  1,240.    Elapsed: 0:03:18.\n","  Batch   440  of  1,240.    Elapsed: 0:03:37.\n","  Batch   480  of  1,240.    Elapsed: 0:03:57.\n","  Batch   520  of  1,240.    Elapsed: 0:04:17.\n","  Batch   560  of  1,240.    Elapsed: 0:04:36.\n","  Batch   600  of  1,240.    Elapsed: 0:04:56.\n","  Batch   640  of  1,240.    Elapsed: 0:05:15.\n","  Batch   680  of  1,240.    Elapsed: 0:05:35.\n","  Batch   720  of  1,240.    Elapsed: 0:05:55.\n","  Batch   760  of  1,240.    Elapsed: 0:06:14.\n","  Batch   800  of  1,240.    Elapsed: 0:06:34.\n","  Batch   840  of  1,240.    Elapsed: 0:06:53.\n","  Batch   880  of  1,240.    Elapsed: 0:07:13.\n","  Batch   920  of  1,240.    Elapsed: 0:07:32.\n","  Batch   960  of  1,240.    Elapsed: 0:07:52.\n","  Batch 1,000  of  1,240.    Elapsed: 0:08:12.\n","  Batch 1,040  of  1,240.    Elapsed: 0:08:31.\n","  Batch 1,080  of  1,240.    Elapsed: 0:08:51.\n","  Batch 1,120  of  1,240.    Elapsed: 0:09:11.\n","  Batch 1,160  of  1,240.    Elapsed: 0:09:30.\n","  Batch 1,200  of  1,240.    Elapsed: 0:09:50.\n","\n","  Average training loss: 0.17\n","  Training epcoh took: 0:10:09\n","\n","Running Validation...\n","  Accuracy: 0.91\n","  Validation Loss: 0.30\n","  Validation took: 0:00:48\n","\n","======== Epoch 4 / 4 ========\n","Training...\n","  Batch    40  of  1,240.    Elapsed: 0:00:22.\n","  Batch    80  of  1,240.    Elapsed: 0:00:41.\n","  Batch   120  of  1,240.    Elapsed: 0:01:01.\n","  Batch   160  of  1,240.    Elapsed: 0:01:20.\n","  Batch   200  of  1,240.    Elapsed: 0:01:40.\n","  Batch   240  of  1,240.    Elapsed: 0:02:00.\n","  Batch   280  of  1,240.    Elapsed: 0:02:19.\n","  Batch   320  of  1,240.    Elapsed: 0:02:39.\n","  Batch   360  of  1,240.    Elapsed: 0:02:58.\n","  Batch   400  of  1,240.    Elapsed: 0:03:18.\n","  Batch   440  of  1,240.    Elapsed: 0:03:38.\n","  Batch   480  of  1,240.    Elapsed: 0:03:57.\n","  Batch   520  of  1,240.    Elapsed: 0:04:17.\n","  Batch   560  of  1,240.    Elapsed: 0:04:36.\n","  Batch   600  of  1,240.    Elapsed: 0:04:56.\n","  Batch   640  of  1,240.    Elapsed: 0:05:16.\n","  Batch   680  of  1,240.    Elapsed: 0:05:35.\n","  Batch   720  of  1,240.    Elapsed: 0:05:55.\n","  Batch   760  of  1,240.    Elapsed: 0:06:14.\n","  Batch   800  of  1,240.    Elapsed: 0:06:34.\n","  Batch   840  of  1,240.    Elapsed: 0:06:53.\n","  Batch   880  of  1,240.    Elapsed: 0:07:13.\n","  Batch   920  of  1,240.    Elapsed: 0:07:33.\n","  Batch   960  of  1,240.    Elapsed: 0:07:52.\n","  Batch 1,000  of  1,240.    Elapsed: 0:08:12.\n","  Batch 1,040  of  1,240.    Elapsed: 0:08:31.\n","  Batch 1,080  of  1,240.    Elapsed: 0:08:51.\n","  Batch 1,120  of  1,240.    Elapsed: 0:09:11.\n","  Batch 1,160  of  1,240.    Elapsed: 0:09:30.\n","  Batch 1,200  of  1,240.    Elapsed: 0:09:50.\n","\n","  Average training loss: 0.12\n","  Training epcoh took: 0:10:09\n","\n","Running Validation...\n","  Accuracy: 0.91\n","  Validation Loss: 0.36\n","  Validation took: 0:00:48\n","\n","Training complete!\n","Total training took 0:43:54 (h:mm:ss)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hC_zFVW04TX5"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"seUXpyjs4TVQ"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zkee7l4X4TSz"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhVyjiTX4TPv"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nvwlxCDB4TMo"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_yAy5UEy4TCm"},"source":[""],"execution_count":null,"outputs":[]}]}